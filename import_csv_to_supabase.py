#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSV åŒ¯å…¥ Supabase è…³æœ¬
å°‡ tasks_rows.csv æª”æ¡ˆåŒ¯å…¥åˆ° Supabase çš„ tasks è¡¨
"""

import csv
import json
import requests
import sys
import os
from datetime import datetime
from typing import Dict, Any, Optional

# ========================================
# Supabase é…ç½®
# ========================================
# é è¨­å€¼ï¼ˆæœ¬åœ°é–‹ç™¼ç’°å¢ƒï¼‰
SUPABASE_URL = os.getenv('SUPABASE_URL', 'http://192.168.62.101:54321')
SUPABASE_ANON_KEY = os.getenv('SUPABASE_ANON_KEY', 'sb_publishable_ACJWlzQHlZjBrEguHvfOxg_3BJgxAaH')

# Supabase REST API ç«¯é»
API_BASE_URL = f"{SUPABASE_URL}/rest/v1"


def create_headers() -> Dict[str, str]:
    """å»ºç«‹ Supabase API è«‹æ±‚æ¨™é ­"""
    return {
        'apikey': SUPABASE_ANON_KEY,
        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',
        'Content-Type': 'application/json',
        'Prefer': 'return=representation'
    }


def parse_date(date_str: str) -> Optional[str]:
    """è§£ææ—¥æœŸå­—ä¸²ï¼Œè½‰æ›ç‚º YYYY-MM-DD æ ¼å¼"""
    if not date_str or date_str.strip() == '':
        return None
    
    date_str = date_str.strip()
    
    # å˜—è©¦å¤šç¨®æ—¥æœŸæ ¼å¼
    date_formats = [
        '%Y-%m-%d',
        '%Y/%m/%d',
        '%m/%d/%Y',
        '%d/%m/%Y',
        '%Y-%m-%d %H:%M:%S',
        '%Y/%m/%d %H:%M:%S',
    ]
    
    for fmt in date_formats:
        try:
            dt = datetime.strptime(date_str, fmt)
            return dt.strftime('%Y-%m-%d')
        except ValueError:
            continue
    
    # å¦‚æœéƒ½ç„¡æ³•è§£æï¼Œè¿”å› None
    print(f"âš ï¸  ç„¡æ³•è§£ææ—¥æœŸï¼š{date_str}")
    return None


def parse_json_field(json_str: str) -> Any:
    """è§£æ JSON å­—ä¸²æ¬„ä½ï¼ˆå¦‚ collaborator_ids, evidenceï¼‰"""
    if not json_str or json_str.strip() == '':
        return []
    
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå˜—è©¦è§£æç‚ºé€—è™Ÿåˆ†éš”çš„æ•¸å­—åˆ—è¡¨
        try:
            values = [int(x.strip()) for x in json_str.split(',') if x.strip()]
            return values
        except ValueError:
            return []


def convert_row_to_task(row: Dict[str, str], row_num: int) -> Optional[Dict[str, Any]]:
    """
    å°‡ CSV è¡Œè½‰æ›ç‚º Supabase tasks è¡¨æ ¼å¼
    
    tasks è¡¨æ¬„ä½ï¼š
    - id (BIGINT)
    - timestamp (TIMESTAMPTZ) - è‡ªå‹•ç”Ÿæˆ
    - title (TEXT)
    - description (TEXT)
    - assigner_id (BIGINT)
    - assigner_name (TEXT)
    - assignee_id (BIGINT)
    - assignee_name (TEXT)
    - collaborator_ids (JSONB)
    - role_category (TEXT)
    - plan_date (DATE)
    - interim_date (DATE)
    - final_date (DATE)
    - status (TEXT)
    - assignee_response (TEXT)
    - evidence (JSONB)
    """
    try:
        # ç”Ÿæˆä»»å‹™ IDï¼ˆå¦‚æœ CSV ä¸­æ²’æœ‰ï¼‰
        task_id = None
        if 'id' in row and row['id'].strip():
            try:
                task_id = int(row['id'].strip())
            except ValueError:
                task_id = int(datetime.now().timestamp() * 1000) + row_num
        
        if task_id is None:
            task_id = int(datetime.now().timestamp() * 1000) + row_num
        
        # å»ºç«‹ä»»å‹™è³‡æ–™
        task_data = {
            'id': task_id,
            'title': row.get('title', '').strip() or f'ä»»å‹™ {row_num}',
            'description': row.get('description', '').strip() or None,
            'assigner_id': int(row['assigner_id'].strip()) if row.get('assigner_id', '').strip() else None,
            'assigner_name': row.get('assigner_name', '').strip() or None,
            'assignee_id': int(row['assignee_id'].strip()) if row.get('assignee_id', '').strip() else None,
            'assignee_name': row.get('assignee_name', '').strip() or None,
            'collaborator_ids': parse_json_field(row.get('collaborator_ids', '[]')),
            'role_category': row.get('role_category', '').strip() or None,
            'plan_date': parse_date(row.get('plan_date', '')),
            'interim_date': parse_date(row.get('interim_date', '')),
            'final_date': parse_date(row.get('final_date', '')),
            'status': row.get('status', 'pending').strip() or 'pending',
            'assignee_response': row.get('assignee_response', '').strip() or None,
            'evidence': parse_json_field(row.get('evidence', '[]'))
        }
        
        return task_data
    
    except Exception as e:
        print(f"âŒ ç¬¬ {row_num} è¡Œè½‰æ›å¤±æ•—ï¼š{e}")
        return None


def import_csv_to_supabase(csv_file_path: str, batch_size: int = 10) -> None:
    """
    å¾ CSV æª”æ¡ˆåŒ¯å…¥è³‡æ–™åˆ° Supabase
    
    Args:
        csv_file_path: CSV æª”æ¡ˆè·¯å¾‘
        batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆä¸€æ¬¡åŒ¯å…¥å¤šå°‘ç­†ï¼‰
    """
    print("=" * 60)
    print("ğŸ“¥ é–‹å§‹åŒ¯å…¥ CSV åˆ° Supabase")
    print("=" * 60)
    print(f"ğŸ“ CSV æª”æ¡ˆï¼š{csv_file_path}")
    print(f"ğŸŒ Supabase URLï¼š{SUPABASE_URL}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°ï¼š{batch_size}")
    print()
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(csv_file_path):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {csv_file_path}")
        sys.exit(1)
    
    # è®€å– CSV æª”æ¡ˆ
    tasks = []
    total_rows = 0
    success_count = 0
    error_count = 0
    
    try:
        with open(csv_file_path, 'r', encoding='utf-8-sig') as f:
            # è‡ªå‹•åµæ¸¬åˆ†éš”ç¬¦è™Ÿ
            sample = f.read(1024)
            f.seek(0)
            sniffer = csv.Sniffer()
            delimiter = sniffer.sniff(sample).delimiter
            
            reader = csv.DictReader(f, delimiter=delimiter)
            
            print(f"ğŸ“‹ CSV æ¬„ä½ï¼š{reader.fieldnames}")
            print()
            
            for row_num, row in enumerate(reader, start=2):  # å¾ç¬¬ 2 è¡Œé–‹å§‹ï¼ˆç¬¬ 1 è¡Œæ˜¯æ¨™é¡Œï¼‰
                total_rows += 1
                task = convert_row_to_task(row, row_num)
                
                if task:
                    tasks.append(task)
                    print(f"âœ… ç¬¬ {row_num} è¡Œï¼šå·²è½‰æ›ï¼ˆID: {task['id']}, æ¨™é¡Œ: {task['title'][:30]}...ï¼‰")
                else:
                    error_count += 1
                    print(f"âŒ ç¬¬ {row_num} è¡Œï¼šè½‰æ›å¤±æ•—")
        
        print()
        print(f"ğŸ“Š ç¸½å…±è®€å– {total_rows} è¡Œï¼ŒæˆåŠŸè½‰æ› {len(tasks)} ç­†ï¼Œå¤±æ•— {error_count} ç­†")
        print()
        
        # æ‰¹æ¬¡åŒ¯å…¥åˆ° Supabase
        if not tasks:
            print("âš ï¸  æ²’æœ‰å¯åŒ¯å…¥çš„è³‡æ–™")
            return
        
        print("=" * 60)
        print("ğŸš€ é–‹å§‹åŒ¯å…¥åˆ° Supabase")
        print("=" * 60)
        
        for i in range(0, len(tasks), batch_size):
            batch = tasks[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (len(tasks) + batch_size - 1) // batch_size
            
            print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_num}/{total_batches}ï¼ˆ{len(batch)} ç­†ï¼‰")
            
            try:
                response = requests.post(
                    f"{API_BASE_URL}/tasks",
                    headers=create_headers(),
                    json=batch
                )
                
                if response.status_code == 201:
                    result = response.json()
                    inserted_count = len(result) if isinstance(result, list) else 1
                    success_count += inserted_count
                    print(f"âœ… æˆåŠŸåŒ¯å…¥ {inserted_count} ç­†")
                    
                    # é¡¯ç¤ºåŒ¯å…¥çš„ä»»å‹™ ID
                    if isinstance(result, list):
                        ids = [str(task['id']) for task in result]
                        print(f"   ID: {', '.join(ids)}")
                
                elif response.status_code == 409:
                    # è¡çªï¼ˆID å·²å­˜åœ¨ï¼‰ï¼Œå˜—è©¦æ›´æ–°
                    print(f"âš ï¸  éƒ¨åˆ†ä»»å‹™ ID å·²å­˜åœ¨ï¼Œå˜—è©¦æ›´æ–°...")
                    for task in batch:
                        try:
                            update_response = requests.patch(
                                f"{API_BASE_URL}/tasks?id=eq.{task['id']}",
                                headers=create_headers(),
                                json=task
                            )
                            if update_response.status_code in [200, 204]:
                                success_count += 1
                                print(f"   âœ… å·²æ›´æ–°ä»»å‹™ ID: {task['id']}")
                            else:
                                error_count += 1
                                print(f"   âŒ æ›´æ–°å¤±æ•— ID: {task['id']}, éŒ¯èª¤: {update_response.text}")
                        except Exception as e:
                            error_count += 1
                            print(f"   âŒ æ›´æ–°ä»»å‹™ ID {task['id']} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                
                else:
                    error_count += len(batch)
                    print(f"âŒ åŒ¯å…¥å¤±æ•—ï¼šHTTP {response.status_code}")
                    print(f"   éŒ¯èª¤è¨Šæ¯ï¼š{response.text}")
            
            except Exception as e:
                error_count += len(batch)
                print(f"âŒ æ‰¹æ¬¡åŒ¯å…¥æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        
        print()
        print("=" * 60)
        print("ğŸ“Š åŒ¯å…¥çµæœçµ±è¨ˆ")
        print("=" * 60)
        print(f"âœ… æˆåŠŸï¼š{success_count} ç­†")
        print(f"âŒ å¤±æ•—ï¼š{error_count} ç­†")
        print(f"ğŸ“‹ ç¸½è¨ˆï¼š{total_rows} ç­†")
        print()
        
        if success_count > 0:
            print("ğŸ‰ åŒ¯å…¥å®Œæˆï¼")
        else:
            print("âš ï¸  æ²’æœ‰æˆåŠŸåŒ¯å…¥ä»»ä½•è³‡æ–™")
    
    except Exception as e:
        print(f"âŒ è®€å– CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        sys.exit(1)


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å°‡ CSV æª”æ¡ˆåŒ¯å…¥ Supabase tasks è¡¨')
    parser.add_argument('csv_file', nargs='?', default='tasks_rows.csv',
                       help='CSV æª”æ¡ˆè·¯å¾‘ï¼ˆé è¨­ï¼štasks_rows.csvï¼‰')
    parser.add_argument('--url', default=None,
                       help=f'Supabase URLï¼ˆé è¨­ï¼š{SUPABASE_URL}ï¼‰')
    parser.add_argument('--key', default=None,
                       help='Supabase Anon Keyï¼ˆé è¨­ï¼šå¾ç’°å¢ƒè®Šæ•¸æˆ–ä½¿ç”¨é è¨­å€¼ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10,
                       help='æ‰¹æ¬¡å¤§å°ï¼ˆé è¨­ï¼š10ï¼‰')
    
    args = parser.parse_args()
    
    # æ›´æ–°é…ç½®
    global SUPABASE_URL, SUPABASE_ANON_KEY, API_BASE_URL
    if args.url:
        SUPABASE_URL = args.url
        API_BASE_URL = f"{SUPABASE_URL}/rest/v1"
    if args.key:
        SUPABASE_ANON_KEY = args.key
    
    # åŸ·è¡ŒåŒ¯å…¥
    import_csv_to_supabase(args.csv_file, args.batch_size)


if __name__ == '__main__':
    main()

